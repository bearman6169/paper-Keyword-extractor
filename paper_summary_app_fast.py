import streamlit as st
import pandas as pd
import re
import os
import gc
import time
import tempfile
from io import BytesIO
from zipfile import ZipFile

# ë¬´ê±°ìš´ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì€ í•„ìš”í•  ë•Œë§Œ ë¡œë“œí•˜ë„ë¡ í•¨ìˆ˜í™”
def load_fitz():
    """PyMuPDF ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í•„ìš”í•œ ì‹œì ì— ë¡œë“œ"""
    import fitz
    return fitz

# ìš”ì•½ ëª¨ë¸ (í•„ìš”í•  ë•Œë§Œ ë¡œë“œí•˜ëŠ” ì§€ì—° ë¡œë”© íŒ¨í„´ ì ìš©)
def get_summarizer():
    """ìš”ì•½ ëª¨ë¸ ë¡œë“œ - í•„ìš”í•  ë•Œë§Œ ë©”ëª¨ë¦¬ì— ë¡œë“œ"""
    from transformers import pipeline
    # ê°€ë²¼ìš´ ëª¨ë¸ ì„ íƒ (BART-baseëŠ” Pegasusë³´ë‹¤ ê°€ë²¼ì›€)
    return pipeline("summarization", model="sshleifer/distilbart-cnn-12-6", device=-1)  # CPU ì‚¬ìš©

# í‚¤ì›Œë“œ ì¶”ì¶œ ëª¨ë¸ (í•„ìš”í•  ë•Œë§Œ ë¡œë“œ)
def get_keyword_model():
    """í‚¤ì›Œë“œ ì¶”ì¶œ ëª¨ë¸ ë¡œë“œ - í•„ìš”í•  ë•Œë§Œ ë©”ëª¨ë¦¬ì— ë¡œë“œ"""
    from keybert import KeyBERT
    # ê°€ë²¼ìš´ ì„ë² ë”© ëª¨ë¸ ì‚¬ìš© (ê¸°ë³¸ all-MiniLM-L6-v2)
    return KeyBERT()

# ë©”ì¸ ì¸í„°í˜ì´ìŠ¤ ì„¤ì •
st.set_page_config(page_title="ğŸ“„ ë…¼ë¬¸ ìš”ì•½ê¸°", layout="wide")
st.title("ğŸ“„ ë…¼ë¬¸ ìš”ì•½ ë„êµ¬ (ìµœì í™”ëœ ë²„ì „)")

# ë°°ì¹˜ í”„ë¡œì„¸ì‹±ì„ ìœ„í•œ ì„¤ì •
st.sidebar.title("âš™ï¸ ì„¤ì •")
batch_size = st.sidebar.slider("ë°°ì¹˜ ì‚¬ì´ì¦ˆ (í•œ ë²ˆì— ì²˜ë¦¬í•  PDF ìˆ˜)", 1, 5, 3)
enable_summarization = st.sidebar.checkbox("í…ìŠ¤íŠ¸ ìš”ì•½ í™œì„±í™”", True)
enable_keyword = st.sidebar.checkbox("í‚¤ì›Œë“œ ì¶”ì¶œ í™œì„±í™”", True)

# PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ í•¨ìˆ˜
@st.cache_data(show_spinner=False)
def extract_text_from_pdf(pdf_content):
    """PDFì—ì„œ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ (ë©”ëª¨ë¦¬ ìµœì í™”)"""
    fitz = load_fitz()
    
    # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥í•˜ì—¬ ë©”ëª¨ë¦¬ ë¶€ë‹´ ì¤„ì´ê¸°
    with tempfile.NamedTemporaryFile(suffix=".pdf", delete=False) as temp_file:
        temp_file.write(pdf_content)
        temp_path = temp_file.name
    
    try:
        # ë¬¸ì„œë¥¼ ì‘ì€ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
        with fitz.open(temp_path) as doc:
            # ì²« í˜ì´ì§€ í…ìŠ¤íŠ¸ë§Œ ë³„ë„ ì¶”ì¶œ (ë©”íƒ€ë°ì´í„°ìš©)
            first_page_text = doc[0].get_text() if doc.page_count > 0 else ""
            
            # ì „ì²´ í…ìŠ¤íŠ¸ëŠ” ìµœëŒ€ 20í˜ì´ì§€ê¹Œì§€ë§Œ ì²˜ë¦¬ (ë©”ëª¨ë¦¬ ì ˆì•½)
            max_pages = min(20, doc.page_count)
            all_text = "\n".join([doc[i].get_text() for i in range(max_pages)])
    finally:
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        if os.path.exists(temp_path):
            os.unlink(temp_path)
    
    return all_text, first_page_text

# ê²°ë¡  ì¶”ì¶œ í•¨ìˆ˜
def extract_conclusion(text):
    """PDFì—ì„œ ê²°ë¡  ë¶€ë¶„ë§Œ ì¶”ì¶œ"""
    text = text.lower()
    conclusion_text = ""
    
    # ê²°ë¡  ì„¹ì…˜ ì°¾ê¸°
    for marker in ["conclusion", "conclusions", "summary"]:
        match = re.search(r"\b" + marker + r"\b", text)
        if match:
            start = match.end()
            end = len(text)
            
            # ë‹¤ìŒ ì„¹ì…˜ ì°¾ê¸°
            for stop in ["reference", "acknowledgment", "bibliography"]:
                pos = text.find(stop, start)
                if pos != -1:
                    end = min(end, pos)
            
            conclusion_text = text[start:end].strip()
            break
    
    # ë„ˆë¬´ ê¸´ ê²½ìš° ìµœëŒ€ 1000ìë¡œ ì œí•œ (ë©”ëª¨ë¦¬ ì ˆì•½)
    return conclusion_text[:1000] if conclusion_text else text[:1000]

# ì œëª©ê³¼ ì €ì ì¶”ì¶œ í•¨ìˆ˜ (ê°„ì†Œí™”ëœ ë²„ì „)
def extract_metadata(text):
    """ì œëª©ê³¼ ì €ì ì •ë³´ ì¶”ì¶œ (ê°„ì†Œí™”ëœ ë²„ì „)"""
    lines = [line.strip() for line in text.split('\n') if line.strip()]
    
    # ì œëª©ì€ ë³´í†µ ì²˜ìŒ ëª‡ ì¤„ ì¤‘ ê°€ì¥ ê¸´ ì¤„
    title_candidates = [line for line in lines[:10] if 3 < len(line.split()) < 20]
    title = max(title_candidates, key=len) if title_candidates else "ì œëª© ì¶”ì¶œ ì‹¤íŒ¨"
    
    # ì €ìëŠ” ë³´í†µ ì´ë©”ì¼ì´ë‚˜ ì†Œì†ì´ í¬í•¨ëœ ì¤„ ê·¼ì²˜
    author = "ì €ì ì •ë³´ ì—†ìŒ"
    for i, line in enumerate(lines[:20]):
        if '@' in line or ('university' in line.lower() and i > 0):
            author = lines[i-1]
            break
    
    return title, author

# ë°°ì¹˜ ì²˜ë¦¬ í•¨ìˆ˜
def process_pdfs_in_batches(files, batch_size=3):
    """PDF íŒŒì¼ë“¤ì„ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬"""
    results = []
    
    # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
    for i in range(0, len(files), batch_size):
        batch = files[i:i+batch_size]
        batch_progress = st.progress(0)
        
        for j, file in enumerate(batch):
            # ì§„í–‰ìƒí™© í‘œì‹œ
            progress_text = f"ì²˜ë¦¬ ì¤‘: {file.name} ({j+1}/{len(batch)})"
            st.text(progress_text)
            batch_progress.progress((j+1)/len(batch))
            
            try:
                # PDF íŒŒì¼ ì½ê¸°
                pdf_bytes = file.read()
                file.seek(0)  # íŒŒì¼ í¬ì¸í„° ë¦¬ì…‹
                
                # í…ìŠ¤íŠ¸ ì¶”ì¶œ
                full_text, first_page = extract_text_from_pdf(pdf_bytes)
                
                # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
                title, author = extract_metadata(first_page)
                
                # ê²°ë¡  ì¶”ì¶œ
                conclusion = extract_conclusion(full_text)
                
                # ìš”ì•½ ë° í‚¤ì›Œë“œ ì¶”ì¶œ (ì„ íƒì )
                summary = "ìš”ì•½ ê¸°ëŠ¥ ë¹„í™œì„±í™”ë¨"
                keywords = "í‚¤ì›Œë“œ ê¸°ëŠ¥ ë¹„í™œì„±í™”ë¨"
                
                if enable_summarization and conclusion:
                    # ìš”ì•½ ëª¨ë¸ ë¡œë“œ ë° ìš”ì•½ ìƒì„±
                    summarizer = get_summarizer()
                    summary = summarizer(conclusion[:500], max_length=80, min_length=30, 
                                       do_sample=False)[0]["summary_text"]
                    # ëª¨ë¸ ì œê±°
                    del summarizer
                    gc.collect()
                
                if enable_keyword and full_text:
                    # í‚¤ì›Œë“œ ëª¨ë¸ ë¡œë“œ ë° í‚¤ì›Œë“œ ì¶”ì¶œ
                    kw_model = get_keyword_model()
                    keywords_raw = kw_model.extract_keywords(full_text[:5000], 
                                                           keyphrase_ngram_range=(1, 2), 
                                                           stop_words='english', 
                                                           top_n=5)
                    keywords = ", ".join([k[0] for k in keywords_raw if len(k[0]) >= 3])
                    # ëª¨ë¸ ì œê±°
                    del kw_model
                    gc.collect()
                
                # ê²°ê³¼ ì €ì¥
                results.append({
                    "íŒŒì¼ëª…": file.name,
                    "ì œëª©": title,
                    "ì €ì": author,
                    "ê²°ë¡  ìš”ì•½": summary,
                    "í‚¤ì›Œë“œ": keywords
                })
                
                # ë©”ëª¨ë¦¬ í™•ë³´
                del full_text, first_page, conclusion
                gc.collect()
                
            except Exception as e:
                st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {file.name} - {str(e)}")
                # ì˜¤ë¥˜ê°€ ë°œìƒí•´ë„ ê³„ì† ì²˜ë¦¬
                results.append({
                    "íŒŒì¼ëª…": file.name,
                    "ì œëª©": "ì˜¤ë¥˜ ë°œìƒ",
                    "ì €ì": "ì˜¤ë¥˜ ë°œìƒ",
                    "ê²°ë¡  ìš”ì•½": f"ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}",
                    "í‚¤ì›Œë“œ": "ì˜¤ë¥˜"
                })
            
        # ë°°ì¹˜ ì™„ë£Œ í›„ ë©”ëª¨ë¦¬ ì •ë¦¬
        batch_progress.empty()
        gc.collect()
    
    return results

# ë©”ì¸ í”„ë¡œê·¸ë¨ UI
uploaded_files = st.file_uploader("ğŸ“¥ PDF íŒŒì¼ ì—…ë¡œë“œ (ì—¬ëŸ¬ ê°œ ì„ íƒ ê°€ëŠ¥)", 
                                type="pdf", 
                                accept_multiple_files=True)

if uploaded_files:
    st.info(f"ğŸ“‚ {len(uploaded_files)}ê°œ íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤. 'ìš”ì•½ ì‹œì‘' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
    
    if st.button("ğŸš€ ìš”ì•½ ì‹œì‘"):
        start_time = time.time()
        
        with st.spinner("ë…¼ë¬¸ ë¶„ì„ ì¤‘... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”"):
            # ë°°ì¹˜ ì²˜ë¦¬ ì‹¤í–‰
            results = process_pdfs_in_batches(uploaded_files, batch_size)
            
            # ë°ì´í„°í”„ë ˆì„ ìƒì„±
            if results:
                df = pd.DataFrame(results)
                
                # ê²°ê³¼ í‘œì‹œ
                st.success(f"âœ… {len(results)}ê°œ PDF ì²˜ë¦¬ ì™„ë£Œ! ({time.time() - start_time:.1f}ì´ˆ ì†Œìš”)")
                st.dataframe(df)
                
                # ê²°ê³¼ ë‹¤ìš´ë¡œë“œ ì¤€ë¹„
                buffer = BytesIO()
                with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                    df.to_excel(writer, index=False, sheet_name='ë…¼ë¬¸ìš”ì•½')
                buffer.seek(0)
                
                # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                st.download_button(
                    label="ğŸ“¥ Excel íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ",
                    data=buffer,
                    file_name="ë…¼ë¬¸_ìš”ì•½_ê²°ê³¼.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            else:
                st.error("ì²˜ë¦¬ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
